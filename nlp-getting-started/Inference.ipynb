{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+3\">Inference Notebook</font>\n",
    "\n",
    "Explore simple ML models, different text embeddings, hyper parameter tuning and ensemble models.\n",
    "\n",
    "The BERT model got an accuracy of about 0.83 without any feature engineering. It will be interesting to see if traditional ML models can be tuned to perform as well/better than BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score, log_loss\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train_df.columns if col not in ['target','id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train_df[features], train_df['target'], test_size=0.1,\n",
    "                                                 shuffle=True, random_state = 42)\n",
    "\n",
    "xtest = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7389</th>\n",
       "      <td>windstorm</td>\n",
       "      <td>Argus Industries \\m/666\\m/</td>\n",
       "      <td>Damn...was wondering where my drone ended up a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>tragedy</td>\n",
       "      <td>MÌ©xico</td>\n",
       "      <td>I'm gunning down romance\\nIt never did a thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>sunk</td>\n",
       "      <td>{GoT | Modern AU | Lizz}</td>\n",
       "      <td>@UntamedDirewolf 'I... Wow. Alright.' Sansa sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>inundated</td>\n",
       "      <td>The windy plains of Denver</td>\n",
       "      <td>@VZWSupport do texts use data? She was inundat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7247</th>\n",
       "      <td>weapons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@kirstiealley @_AnimalAdvocate Or pay it for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>body%20bags</td>\n",
       "      <td>Austin, Texas</td>\n",
       "      <td>@FoxNews @JenGriffinFNC When you call to repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>engulfed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Men escape car engulfed in flames in Parley's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6501</th>\n",
       "      <td>survive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@lucypalladino and I don't have any classes to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>apocalypse</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>Julie + R is the apocalypse version of Romeo +...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>evacuated</td>\n",
       "      <td>Denver, Colorado</td>\n",
       "      <td>13000 evacuated as California firefighters fig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyword                    location  \\\n",
       "7389    windstorm  Argus Industries \\m/666\\m/   \n",
       "6804      tragedy                     MÌ©xico   \n",
       "6478         sunk    {GoT | Modern AU | Lizz}   \n",
       "4641    inundated  The windy plains of Denver   \n",
       "7247      weapons                         NaN   \n",
       "1018  body%20bags               Austin, Texas   \n",
       "3268     engulfed                         NaN   \n",
       "6501      survive                         NaN   \n",
       "282    apocalypse                     Oakland   \n",
       "3333    evacuated            Denver, Colorado   \n",
       "\n",
       "                                                   text  \n",
       "7389  Damn...was wondering where my drone ended up a...  \n",
       "6804  I'm gunning down romance\\nIt never did a thing...  \n",
       "6478  @UntamedDirewolf 'I... Wow. Alright.' Sansa sh...  \n",
       "4641  @VZWSupport do texts use data? She was inundat...  \n",
       "7247  @kirstiealley @_AnimalAdvocate Or pay it for a...  \n",
       "1018  @FoxNews @JenGriffinFNC When you call to repor...  \n",
       "3268  Men escape car engulfed in flames in Parley's ...  \n",
       "6501  @lucypalladino and I don't have any classes to...  \n",
       "282   Julie + R is the apocalypse version of Romeo +...  \n",
       "3333  13000 evacuated as California firefighters fig...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric\n",
    "\n",
    "As per the competition rules. We will optimise for the F1_Score and also use the log_loss to evaluate each algorithms performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "As we will evalute different levels of text preprocessing, the processing steps will be kept in a seperate file so they can easily be added to as we evaluate each model. This will enable us to add different level of preprocessing to the pipelines.\n",
    "\n",
    "See `TweetProcessor` in `text_preprocessing.py` for text cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from text_preprocessing import TweetProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TweetProcessor()\n",
    "xtrain['text'] = tp.process_text(xtrain['text'])\n",
    "xvalid['text'] = tp.process_text(xvalid['text'])\n",
    "xtest['text'] = tp.process_text(xtest['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple ML Models\n",
    "\n",
    "To begin with we will just evaluate the `text` column and create features from that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words\n",
    "\n",
    "There are a number of different methods for generating numerical features from text. We can try the following:\n",
    "- TF-IDF\n",
    "- CountVectorizer\n",
    "\n",
    "We will create features from using each method and evaluate which works better on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF embeddings\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Count Vectorizer\n",
    "ctv = CountVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The first model to try is a simple logistic regression. We will use sklearn pipelines and gridsearch to find the best possible logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary to store results of each model\n",
    "model_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard logistic regresssion\n",
    "lr_pipe_tfv = Pipeline([('tfv',tfv),\n",
    "                        ('lr',LogisticRegression())])\n",
    "\n",
    "lr_pipe_ctv = Pipeline([('ctv',ctv),\n",
    "                        ('lr',LogisticRegression())])\n",
    "\n",
    "#gridsearch parameters\n",
    "lr_param_grid = {'lr__C': [0.1, 1.0, 10],\n",
    "                'lr__penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipelines with svd and scaling\n",
    "lr_pipe_tfv_svd = Pipeline([('tfv',tfv),\n",
    "                        ('svd',TruncatedSVD()),\n",
    "                        ('scl',StandardScaler()),\n",
    "                        ('lr',LogisticRegression())])\n",
    "\n",
    "lr_pipe_ctv_svd = Pipeline([('ctv',ctv),\n",
    "                        ('svd',TruncatedSVD()),\n",
    "                        ('scl',StandardScaler()),\n",
    "                        ('lr',LogisticRegression())])\n",
    "\n",
    "lr_svd_param_grid = {'svd__n_components' : [120, 180],\n",
    "                 'lr__C': [0.1, 1.0, 10], \n",
    "                 'lr__penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gs_tfv = GridSearchCV(lr_pipe_tfv, param_grid=lr_param_grid, scoring='f1',\n",
    "                     verbose=5, n_jobs=-1, refit=True, cv=4)\n",
    "\n",
    "lr_gs_ctv = GridSearchCV(lr_pipe_ctv, param_grid=lr_param_grid, scoring='f1',\n",
    "                     verbose=5, n_jobs=-1, refit=True, cv=4)\n",
    "\n",
    "lr_svd_gs_tfv = GridSearchCV(lr_pipe_tfv_svd, param_grid=lr_svd_param_grid, scoring='f1',\n",
    "                     verbose=5, n_jobs=-1, refit=True, cv=4)\n",
    "\n",
    "lr_svd_gs_ctv = GridSearchCV(lr_pipe_ctv_svd, param_grid=lr_svd_param_grid, scoring='f1',\n",
    "                     verbose=5, n_jobs=-1, refit=True, cv=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: lr-tfv\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: lr-ctv\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: lr-svd-tfv\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   29.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: lr-svd-ctv\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   39.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyper-parameter tuning done\n"
     ]
    }
   ],
   "source": [
    "models = [lr_gs_tfv, lr_gs_ctv, lr_svd_gs_tfv, lr_svd_gs_ctv]\n",
    "names = ['lr-tfv','lr-ctv','lr-svd-tfv','lr-svd-ctv']\n",
    "\n",
    "for model, name in zip(models,names):\n",
    "    print(f\"\\nTraining model: {name}\")\n",
    "    model.fit(xtrain['text'],ytrain)\n",
    "    \n",
    "print(\"\\nHyper-parameter tuning done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr-tfv: \n",
      "\tBest GridSearch score:  0.7433\n",
      "\tScore on validation set:  0.7227\n",
      "lr-ctv: \n",
      "\tBest GridSearch score:  0.7450\n",
      "\tScore on validation set:  0.7212\n",
      "lr-svd-tfv: \n",
      "\tBest GridSearch score:  0.7261\n",
      "\tScore on validation set:  0.6974\n",
      "lr-svd-ctv: \n",
      "\tBest GridSearch score:  0.7025\n",
      "\tScore on validation set:  0.6902\n"
     ]
    }
   ],
   "source": [
    "def evaluate_gridsearch_models(models,names,xvalid):\n",
    "    val_scores = {}\n",
    "    for model, name in zip(models, names):\n",
    "        print(f\"{name}: \\n\\tBest GridSearch score: {model.best_score_: 0.4f}\")\n",
    "        predictions = model.predict(xvalid)\n",
    "        val_score = f1_score(yvalid,predictions)\n",
    "        print(f\"\\tScore on validation set: {val_score: 0.4f}\")\n",
    "        val_scores[name] = val_score\n",
    "            \n",
    "    return val_scores\n",
    "    \n",
    "\n",
    "lr_val_scores = evaluate_gridsearch_models(models,names,xvalid['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the model with best performance on the unseen validation set is the best Logistic Regression model with CountVectorizer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record best model into dictionary for comparison with other models later\n",
    "model_results['lr-ctv'] = {'model': lr_gs_ctv, 'score': lr_val_scores['lr-ctv']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification report for best logistic regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.499 \n",
      "F1 score: 0.721 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81       426\n",
      "           1       0.78      0.67      0.72       336\n",
      "\n",
      "    accuracy                           0.77       762\n",
      "   macro avg       0.77      0.76      0.76       762\n",
      "weighted avg       0.77      0.77      0.77       762\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_classification_report(model):\n",
    "    \"\"\"Print classification report and confusion matrix\"\"\"\n",
    "    predictions_prob = model.predict_proba(xvalid['text'])\n",
    "    predictions_classes = model.predict(xvalid['text'])\n",
    "\n",
    "    print (\"Log loss: %0.3f \" % log_loss(yvalid, predictions_prob))\n",
    "    print(\"F1 score: %0.3f \" % f1_score(yvalid, predictions_classes))\n",
    "    print(classification_report(yvalid, predictions_classes))\n",
    "\n",
    "    sns.heatmap(confusion_matrix(yvalid,predictions_classes),annot=True,fmt='.0f',cmap='Blues', cbar=False)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "create_classification_report(lr_gs_ctv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline_tfv = Pipeline([('tfv',tfv),\n",
    "                      ('nb',nb)])\n",
    "\n",
    "nb_pipeline_ctv = Pipeline([('ctv',ctv),\n",
    "                      ('nb',nb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_gs_tfv = GridSearchCV(nb_pipeline_tfv, param_grid=nb_param_grid, scoring='f1',\n",
    "                     verbose=5, n_jobs=-1, refit=True, cv=4)\n",
    "\n",
    "nb_gs_ctv = GridSearchCV(nb_pipeline_ctv, param_grid=nb_param_grid, scoring='f1',\n",
    "                     verbose=5, n_jobs=-1, refit=True, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: nb-tfv\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model: nb-ctv\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper-parameter tuning done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "models = [nb_gs_tfv, nb_gs_ctv]\n",
    "names = ['nb-tfv','nb-ctv']\n",
    "\n",
    "for model, name in zip(models,names):\n",
    "    print(f\"\\nTraining model: {name}\")\n",
    "    model.fit(xtrain['text'],ytrain)\n",
    "\n",
    "print(\"Hyper-parameter tuning done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb-tfv: \n",
      "\tBest GridSearch score:  0.7322\n",
      "\tScore on validation set:  0.7092\n",
      "nb-ctv: \n",
      "\tBest GridSearch score:  0.7512\n",
      "\tScore on validation set:  0.7339\n"
     ]
    }
   ],
   "source": [
    "nb_val_scores = evaluate_gridsearch_models(models,names,xvalid['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.763 \n",
      "F1 score: 0.734 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       426\n",
      "           1       0.78      0.69      0.73       336\n",
      "\n",
      "    accuracy                           0.78       762\n",
      "   macro avg       0.78      0.77      0.77       762\n",
      "weighted avg       0.78      0.78      0.78       762\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAARoUlEQVR4nO3ceZSXdb3A8fdnGAaGBIbNQUTcMs1UJI1KUTT3cy293cw9Kzp0LTvXXMgVFQpJW7we6ZZomqKk3tTcLTRNFGVxV0yNRYGUHQQGZ4Dv/eP3Y+7IMsgI/PjOvF/nzDnM8zzz/D6/YXjPM9/nN0RKCUlSPspKPYAkaeMYbknKjOGWpMwYbknKjOGWpMwYbknKjOHWViciKiPi/ohYFBF3fYLznBoRf9mUs5VCRDwcEWeUeg5tPQy3miwiTomIiRGxJCL+VQxMv01w6m8A1UCXlNIJTT1JSum2lNKRm2Cej4iIQyIiRcQ9a2zvXdz+xMc8z+URMWpDx6WUjkkp/aGJ46oZMtxqkog4B7gGGEYhsr2A3wDHbYLT7wi8mVJasQnOtbnMAb4cEV0abDsDeHNTPUAU+G9Ua/GLQhstIjoCQ4AfppTuTiktTSnVpZTuTymdXzymTURcExGzim/XRESb4r5DImJGRJwbEbOLV+vfKe67AhgMnFi8kh+w5pVpROxUvLItL77/7YiYEhEfRMTUiDi1wfaxDT7ugIiYUFyCmRARBzTY90REDI2Ip4vn+UtEdG3k01AL3AucVPz4VsCJwG1rfK7+OyLejYjFETEpIg4qbj8auKjB83ypwRw/i4ingWXALsVt3yvu/5+I+FOD8/88Ih6LiPjYf4HKnuFWU3wZaAvc08gxFwNfAvYFegN9gUsa7O8OdAS2BwYAIyKiU0rpMgpX8XeklLZJKd3Y2CAR8SngWuCYlFJ74ADgxXUc1xl4sHhsF+BXwINrXDGfAnwH2BaoAM5r7LGBW4BvFf98FPAqMGuNYyZQ+Bx0Bm4H7oqItimlR9Z4nr0bfMzpwECgPTB9jfOdC+xd/KZ0EIXP3RnJ/7uiRTHcaoouwNwNLGWcCgxJKc1OKc0BrqAQpNXqivvrUkoPAUuA3Zs4zypgr4ioTCn9K6X02jqO+TfgrZTSrSmlFSml0cAbwFcbHHNTSunNlFINcCeF4K5XSukZoHNE7E4h4Les45hRKaV5xcf8JdCGDT/Pm1NKrxU/pm6N8y2j8Hn8FTAK+FFKacYGzqdmxnCrKeYBXVcvVaxHDz56tTi9uK3+HGuEfxmwzcYOklJaSmGJ4j+Bf0XEgxGxx8eYZ/VM2zd4/70mzHMrcBZwKOv4CSQizouIycXlmYUUfspobAkG4N3GdqaUngOmAEHhG4xaGMOtphgHfAgc38gxsyjcZFytF2svI3xcS4F2Dd7v3nBnSunRlNIRwHYUrqJHfox5Vs80s4kzrXYr8APgoeLVcL3iUsYg4JtAp5RSFbCIQnAB1re80eiyR0T8kMKV+6zi+dXCGG5ttJTSIgo3EEdExPER0S4iWkfEMRFxVfGw0cAlEdGteJNvMIUf7ZviReDgiOhVvDF64eodEVEdEccV17o/pLDksmod53gI+EzxJYzlEXEisCfwQBNnAiClNBXoT2FNf03tgRUUXoFSHhGDgQ4N9r8P7LQxrxyJiM8APwVOo7BkMigiGl3SUfNjuNUkxfXacyjccJxD4cf7syi80gIKcZkIvAy8Ajxf3NaUx/orcEfxXJP4aGzLinPMAuZTiOiZ6zjHPOBYCjf35lG4Uj02pTS3KTOtce6xKaV1/TTxKPAIhZcITgeW89FlkNW/XDQvIp7f0OMUl6ZGAT9PKb2UUnqLwitTbl39ih21DOHNaEnKi1fckpQZwy1JmTHckpQZwy1JmWnsFyg2ico+Z3n3U1ulBROuK/UI0nq1LWe9//+MV9ySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZKS/1APp/bSrKGXPj2VRUlFPeqhX3jHmBn/72IQAu/+FX+foRfVi5chUj//cpfjP6SQB+OegbHHXg51i2vJaBl93Ki2/MKOVTUAuyePFirhh8CW+//SYRwRVDh9F73z7cftut3DH6NsrKWnHwwf358XmDSj1qs2O4tyIf1q7g6IHXsrSmlvLyMh7//Tn85enX2X3n7vTsXkXvfx9KSolunbYB4Kh+e7Jrr27sddwV9N17J6696CQO/tYvSvws1FJcdeXPOLDfQfzymmupq62lZvlyxj/3LE88/hh33X0fFRUVzJs3r9RjNksbDHdE7AEcB2xf3DQTuC+lNHlzDtZSLa2pBaB1eSvKy1uRUmLgCf0446KbSSkBMGfBEgCO7b8Ptz8wHoDxr0yjY/tKunftwHtzF5dmeLUYH3zwAZMmTWDosOEAtK6ooHVFBXfdMZrvfm8gFRUVAHTp0qWUYzZbja5xR8RPgD8CAYwvvgUwOiIu2PzjtTxlZcGzf7yAdx4bzuPPvsGEV6ezc89ufOPI/Rh72yDuve5Mdu3VDYAe21Yx470F9R878/2F9Ni2qlSjqwWZOWMGnTp1ZvDFF/LN/zieywdfzLJly5g+bRrPT5rIqSedwHfPOI1XX3m51KM2Sxu6OTkA+EJKaXhKaVTxbTjQt7hvnSJiYERMjIiJK+a+tinnbfZWrUp86aThfPqoS9h/rx3Zc9ftaFNRzoe1dfQ79SpuuvsZfnfZqaUeUy3cypUreGPy65xw0snc+ad7qays5Pc3XM+KlStZtGgRo0bfyY/PHcT5555d/5OiNp0NhXsV0GMd27cr7lunlNL1KaX9U0r7l3f93CeZr8VatKSGJye+yZEH7MnM9xdw72MvAfDnx19ir90Kq1azZi+kZ/dO9R+zfXUVs2YvLMm8almqq7tTXd2dffbpDcARRx7NG5Nfp7q6msMOP4KIYO999qGsrIwFCxZs4GzaWBsK99nAYxHxcERcX3x7BHgM+K/NP17L0rXTNnTcphKAtm1ac9gX9+Af097n/idepv8XdgPgoP124+13ZgPw4JOvcMqxfQHou/dOLF5S4/q2toiu3bpR3b0706ZOAeC5Z8exy667cuhhhzNh/HMATJs2lbq6Ojp16tTYqdQEjd6cTCk9EhGfobA00vDm5ISU0srNPVxL071rB0YOOZ1WZWWUlQV/+uvzPPzUqzzzwj+5adgZ/OjUr7C05kPOHHI7AI+MfY2j+n2O1+67jGXL6/j+5aNK/AzUklxw0aVc+JPzqKuro2fPHRjy0yuprKxk8KUX8fXjjqV169YM/dlwIqLUozY7sbnXnyr7nOUCl7ZKCyZcV+oRpPVqW856v+P5m5OSlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlJlIKW3WB5g6d/nmfQCpiQY98HqpR5DW665vfz7Wt88rbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKjOGWpMwYbknKTHmpB9BH/WrYYJ57+u9UderM70bdDcAHixcx7NJBvP/eLKq79+CioVfTvkMHxj31N/4wcgRlUUarVq34/n+dz169P1/iZ6Dmqku71px10E5UVZaTEox5cy4PTZ7DiX224ws7VJFILKpZwYix01lQU8f+O3TkpD49SCRWrkrcPH4Gb8xeWuqn0SxESmmzPsDUucs37wM0M6+8OIm2le34xdCL68N9w4hf075DB048fQB33HojSz5YzIAf/JiaZctoW1lJRDDl7TcZdun53DD6zyV+BvkY9MDrpR4hK1WV5XSqbM3U+TW0LS/j51/dg6sfn8K8ZbXU1K0C4JjPdqNnVVtGjnuXtuVlLF9R2N6rUyXnHLIzZ9/j5/zjuuvbn4/17XOpZCuz97770b5Dh49sG/fU3zj8mK8BcPgxX+OZv/8NgMp27Ygo/N0uX15T/2dpc1hYs4Kp82sAWL5iFTMXLadzu9b10QZoU14GxUu11dEGaFtexma+RmxRXCrJwMIF8+nStRsAnbt0ZeGC+fX7nn7yMW767bUsXDCfIb+4rlQjqoXptk0FO3dux1tzC0sfJ/fpwcGf7syy2pVc8chb9cf17dWRU/bbno5ty7lyzD9LNW6z0+Qr7oj4TiP7BkbExIiYOPqWG5v6EFqHiKDhhfWB/Q/jhtF/5rLh13DLyBGlG0wtRtvyMs47ZBduGj+j/mp79AuzOPOuV3lqynyO/my3+mPHv7OIs+95nasen8KJfbYr1cjNzidZKrlifTtSStenlPZPKe1/8rcGfIKHEEBVp87MmzsHgHlz59CxqvNax+y97368N2sGixYu2NLjqQVpFXDuobvw1JT5jH9n4Vr7x06Zzxd3rFpr++T3l1Ddvg3t27TaEmM2e42GOyJeXs/bK0D1FpqxxftSv0MY8/B9AIx5+D6+fNChAMya8Q6rby6/9Y/J1NXW0qHj2v9opE3lzAN3ZOai5Tzw+uz6bd3bt6n/8/47VDFr0fK1tu/cuZLWZcEHH67ccsM2Yxta464GjgLWvIwL4JnNMlELd+VlP+HlFyayeOFCTjv+CE4bcCYnnv5dhl16Po8+cC/bdt+Oi4deDcDYJ8Yw5uH7KS9vTUWbNlw45CpvUGqz2WPbT9H/012YPr+Gq7+2BwC3T5rFV3brQo+ObUkJ5iytZeS4dwD44o5V9N+1MytTonbFKn795NRSjt+sNPpywIi4EbgppTR2HftuTymdsqEH8OWA2lr5ckBtzRp7OWCjV9wppfUuUH+caEuSNj1fxy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmTHckpQZwy1JmYmUUqln0EaIiIEppetLPYe0Jr82txyvuPMzsNQDSOvh1+YWYrglKTOGW5IyY7jz4xqitlZ+bW4h3pyUpMx4xS1JmTHckpQZw52JiDg6Iv4REW9HxAWlnkdaLSJ+HxGzI+LVUs/SUhjuDEREK2AEcAywJ3ByROxZ2qmkejcDR5d6iJbEcOehL/B2SmlKSqkW+CNwXIlnkgBIKf0dmF/qOVoSw52H7YF3G7w/o7hNUgtkuCUpM4Y7DzOBHRq837O4TVILZLjzMAHYLSJ2jogK4CTgvhLPJKlEDHcGUkorgLOAR4HJwJ0ppddKO5VUEBGjgXHA7hExIyIGlHqm5s5feZekzHjFLUmZMdySlBnDLUmZMdySlBnDLUmZMdySlBnDLUmZ+T+1hY8SSF2TcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_classification_report(nb_gs_ctv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record best model into dictionary for comparison with other models later\n",
    "model_results['nb-ctv'] = {'model': nb_gs_ctv, 'score': nb_val_scores['nb-ctv']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glove vectors is another method for generating features from text.\n",
    "\n",
    "Note that the text file containing the embeddings can be downloaded from `http://www-nlp.stanford.edu/data/glove.840B.300d.zip` - it is not included in this git repository due to its large size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1110707it [02:05, 8932.61it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EMBEDDINGS_LOCATION = '../external/glove.840B.300d/glove.840B.300d/glove.840B.300d.txt'\n",
    "\n",
    "\n",
    "# load the GloVe vectors in a dictionary:\n",
    "embeddings_index = {}    \n",
    "f = open(EMBEDDINGS_LOCATION, \"r\", encoding=\"utf8\")\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = ''.join(values[:-300])\n",
    "    coefs = np.asarray(values[-300:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "Finally, we will try an XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(max_df=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe_tfv = Pipeline([('tfv',tfv),\n",
    "                         ('xgb',xgb_clf)\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "xgb_pipe_ctv = Pipeline([('ctv',ctv),\n",
    "                         ('xgb',xgb_clf)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\"xgb__n_estimators\": np.arange(400, 10000, 1000), 'xgb__max_depth': range(1, 20,10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs_tfv = GridSearchCV(xgb_pipe_tfv, param_grid=xgb_param_grid, scoring='f1',\n",
    "                     verbose=10, n_jobs=-1, refit=True, cv=4)\n",
    "\n",
    "xgb_gs_ctv = GridSearchCV(xgb_pipe_ctv, param_grid=xgb_param_grid, scoring='f1',\n",
    "                     verbose=10, n_jobs=-1, refit=True, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs_tfv.fit(xtrain['text'],ytrain)\n",
    "xgb_gs_ctv.fit(xtrain['text'],ytrain)\n",
    "\n",
    "print(\"Hyperparameter tuning complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_classification_report(xgb_gs_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_csv(model,model_name,processed_test_data):\n",
    "    \"\"\"Make preidctions on test set and save to dataframe\n",
    "    \n",
    "    Args:\n",
    "        model: grid search model\n",
    "        model_name (str): name of model to include in the file name of saved model\n",
    "        processed_test_data(df): preprocessed test data\n",
    "\n",
    "    \"\"\"\n",
    "    preds = model.predict(processed_test_data)\n",
    "    final_predictions_df = pd.DataFrame({'id':test_df['id'],'target':preds})\n",
    "    final_predictions_df.to_csv(f\"./submissions/{model_name}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission_csv(clf,'stacking',xtest['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "Many ideas for this notebook can from this [notebook](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle) from Kaggle Grandmaster Abhishek Thakur. I would recommend checking out more of his [content](https://www.youtube.com/user/abhisheksvnit), he has great tutorials particularly on using BERT with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
