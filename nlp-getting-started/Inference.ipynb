{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+3\">Inference Notebook</font>\n",
    "\n",
    "Explore simple ML models, different text embeddings, hyper parameter tuning and ensemble models.\n",
    "\n",
    "The BERT model got an accuracy of about 0.83 without any feature engineering. It will be interesting to see if traditional ML models can be tuned to perform as well/better than BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score, log_loss\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train_df.columns if col not in ['target','id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train_df[features], train_df['target'], test_size=0.1,\n",
    "                                                 shuffle=True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>dust%20storm</td>\n",
       "      <td>Beirut, Lebanon</td>\n",
       "      <td>Some poor sods arriving in Amman during yester...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>hostages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natalie Stavola our co-star explains her role ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4352</th>\n",
       "      <td>hijack</td>\n",
       "      <td>NIGERIA</td>\n",
       "      <td>Bayelsa poll: Tension in Bayelsa as Patience J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>blaze</td>\n",
       "      <td>Gotham City</td>\n",
       "      <td>?? Yes I do have 2 guns ?? ??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>catastrophe</td>\n",
       "      <td>Lytham St Anne's</td>\n",
       "      <td>Oh my god thatÛªs the biggest #gbbo catastrop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>collide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i just remember us driving and singing collide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>mayhem</td>\n",
       "      <td>PG County, MD</td>\n",
       "      <td>Tonight It's Going To Be Mayhem @ #4PlayThursd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>catastrophe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@peterjukes But there are good grounds to beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#MeditationByMSG 45600 ppl got method of medit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>sirens</td>\n",
       "      <td>they/them</td>\n",
       "      <td>my dad said I look thinner than usual but real...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           keyword           location  \\\n",
       "2992  dust%20storm    Beirut, Lebanon   \n",
       "4463      hostages                NaN   \n",
       "4352        hijack            NIGERIA   \n",
       "675          blaze        Gotham City   \n",
       "1486   catastrophe  Lytham St Anne's    \n",
       "1674       collide                NaN   \n",
       "4933        mayhem      PG County, MD   \n",
       "1470   catastrophe                NaN   \n",
       "2238        deluge                NaN   \n",
       "6172        sirens         they/them    \n",
       "\n",
       "                                                   text  \n",
       "2992  Some poor sods arriving in Amman during yester...  \n",
       "4463  Natalie Stavola our co-star explains her role ...  \n",
       "4352  Bayelsa poll: Tension in Bayelsa as Patience J...  \n",
       "675                       ?? Yes I do have 2 guns ?? ??  \n",
       "1486  Oh my god thatÛªs the biggest #gbbo catastrop...  \n",
       "1674  i just remember us driving and singing collide...  \n",
       "4933  Tonight It's Going To Be Mayhem @ #4PlayThursd...  \n",
       "1470  @peterjukes But there are good grounds to beli...  \n",
       "2238  #MeditationByMSG 45600 ppl got method of medit...  \n",
       "6172  my dad said I look thinner than usual but real...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric\n",
    "\n",
    "As per the competition rules. We will optimise for the F1_Score and also use the log_loss to evaluate each algorithms performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "As we will evalute different levels of text preprocessing, the processing steps will be kept in a seperate file so they can easily be added to as we evaluate each model. This will enable us to add different level of preprocessing to the pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from text_preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "To begin with we will just evaluate the `text` column and create features from that.\n",
    "\n",
    "**Create TF-IDF Embeddings**\n",
    "\n",
    "Normally a good place to start with NLP problems. We will first try without any custom preprocessing of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features from 'text'\n",
    "\n",
    "There are a number of different methods for generating numerical features from text. We can try the following:\n",
    "- TF-IDF\n",
    "- CountVectorizer\n",
    "\n",
    "We will create features from using each method and evaluate which works better on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF embeddings\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain['text']) + list(xvalid['text']))\n",
    "xtrain_tfv =  tfv.transform(xtrain['text']) \n",
    "xvalid_tfv = tfv.transform(xvalid['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "ctv = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
    "ctv.fit(list(xtrain['text']) + list(xvalid['text']))\n",
    "xtrain_ctv =  ctv.transform(xtrain['text']) \n",
    "xvalid_ctv = ctv.transform(xvalid['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The first model to try is a simple logistic regression. We will use sklearn pipelines and gridsearch to find the best possible logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary to store results of each model\n",
    "model_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard logistic regresssion\n",
    "lr_pipeline = Pipeline([('lr',LogisticRegression())])\n",
    "\n",
    "#gridsearch parameters\n",
    "lr_param_grid = {'lr__C': [0.1, 1.0, 10],\n",
    "                'lr__penalty': ['l1', 'l2']}\n",
    "\n",
    "\n",
    "#pipeline with svd and scaling\n",
    "lr_pipeline_svd = Pipeline([('svd',TruncatedSVD()),\n",
    "                          ('scl',StandardScaler()),\n",
    "                          ('lr',LogisticRegression())])\n",
    "\n",
    "lr_svd_param_grid = {'svd__n_components' : [120, 180],\n",
    "                 'lr__C': [0.1, 1.0, 10], \n",
    "                 'lr__penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gs_tfv = GridSearchCV(lr_pipeline, param_grid=lr_param_grid, scoring='f1',\n",
    "                     verbose=5, n_jobs=-1, refit=True, cv=4)\n",
    "\n",
    "lr_gs_ctv = GridSearchCV(lr_pipeline, param_grid=lr_param_grid, scoring='f1',\n",
    "                     verbose=5, n_jobs=-1, refit=True, cv=4)\n",
    "\n",
    "lr_svd_gs_tfv = GridSearchCV(lr_pipeline_svd, param_grid=lr_svd_param_grid, scoring='f1',\n",
    "                     verbose=5, n_jobs=-1, refit=True, cv=4)\n",
    "\n",
    "lr_svd_gs_ctv = GridSearchCV(lr_pipeline_svd, param_grid=lr_svd_param_grid, scoring='f1',\n",
    "                     verbose=5, n_jobs=-1, refit=True, cv=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  24 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   19.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   33.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper-parameter tuning done\n"
     ]
    }
   ],
   "source": [
    "lr_gs_tfv.fit(xtrain_tfv, ytrain)\n",
    "lr_gs_ctv.fit(xtrain_ctv, ytrain)\n",
    "lr_svd_gs_tfv.fit(xtrain_tfv, ytrain)\n",
    "lr_svd_gs_ctv.fit(xtrain_ctv, ytrain)\n",
    "\n",
    "print(\"Hyper-parameter tuning done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr-tfv: \n",
      "\tBest GridSearch score:  0.7357\n",
      "\tScore on validation set:  0.7231\n",
      "lr-ctv: \n",
      "\tBest GridSearch score:  0.7423\n",
      "\tScore on validation set:  0.7346\n",
      "lr-svd-tfv: \n",
      "\tBest GridSearch score:  0.7016\n",
      "\tScore on validation set:  0.6831\n",
      "lr-svd-ctv: \n",
      "\tBest GridSearch score:  0.7102\n",
      "\tScore on validation set:  0.6975\n"
     ]
    }
   ],
   "source": [
    "models = [lr_gs_tfv, lr_gs_ctv, lr_svd_gs_tfv, lr_svd_gs_ctv]\n",
    "names = ['lr-tfv','lr-ctv','lr-svd-tfv','lr-svd-ctv']\n",
    "\n",
    "val_scores = {}\n",
    "for model, name in zip(models, names):\n",
    "    print(f\"{name}: \\n\\tBest GridSearch score: {model.best_score_: 0.4f}\")\n",
    "    if 'tfv' in name:\n",
    "        predictions = model.predict(xvalid_tfv)\n",
    "        val_score = f1_score(yvalid,predictions)\n",
    "        print(f\"\\tScore on validation set: {val_score: 0.4f}\")\n",
    "        val_scores[name] = val_score\n",
    "    else:\n",
    "        predictions = model.predict(xvalid_ctv)\n",
    "        val_score = f1_score(yvalid,predictions)\n",
    "        print(f\"\\tScore on validation set: {val_score: 0.4f}\")\n",
    "        val_scores[name] = val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the model with best performance on the unseen validation set is the best Logistic Regression model with CountVectorizer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best model to dictionary for comparison with other models later\n",
    "model_results['lr-ctv'] = {'model': lr_gs_ctv, 'score': val_scores['lr-ctv']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr-ctv': {'model': GridSearchCV(cv=4, error_score=nan,\n",
       "               estimator=Pipeline(memory=None,\n",
       "                                  steps=[('lr',\n",
       "                                          LogisticRegression(C=1.0,\n",
       "                                                             class_weight=None,\n",
       "                                                             dual=False,\n",
       "                                                             fit_intercept=True,\n",
       "                                                             intercept_scaling=1,\n",
       "                                                             l1_ratio=None,\n",
       "                                                             max_iter=100,\n",
       "                                                             multi_class='auto',\n",
       "                                                             n_jobs=None,\n",
       "                                                             penalty='l2',\n",
       "                                                             random_state=None,\n",
       "                                                             solver='lbfgs',\n",
       "                                                             tol=0.0001,\n",
       "                                                             verbose=0,\n",
       "                                                             warm_start=False))],\n",
       "                                  verbose=False),\n",
       "               iid='deprecated', n_jobs=-1,\n",
       "               param_grid={'lr__C': [0.1, 1.0, 10], 'lr__penalty': ['l1', 'l2']},\n",
       "               pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "               scoring='f1', verbose=5), 'score': 0.7346278317152103}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(yvalid,lr_gs.predict_proba(xvalid_tfv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a simple Logistic Regression on TFIDF\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions_prob = clf.predict_proba(xvalid_tfv)\n",
    "predictions_classes = clf.predict(xvalid_tfv)\n",
    "\n",
    "print (\"Log loss: %0.3f \" % log_loss(yvalid, predictions_prob))\n",
    "print(\"F1 score: %0.3f \" % f1_score(yvalid, predictions_classes))\n",
    "print(classification_report(yvalid, predictions_classes))\n",
    "\n",
    "sns.heatmap(confusion_matrix(yvalid,predictions_classes),annot=True,fmt='.0f',cmap='Blues', cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "Many ideas for this notebook can from this [notebook](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle) from Kaggle Grandmaster Abhishek Thakur. I would recommend checking out more of his [content](https://www.youtube.com/user/abhisheksvnit), he has great tutorials particularly on using BERT with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
